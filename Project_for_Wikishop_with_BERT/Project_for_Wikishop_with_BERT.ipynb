{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ознакомление-с-данными\" data-toc-modified-id=\"Ознакомление-с-данными-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Ознакомление с данными</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Предобработка данных</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-классических-моделей\" data-toc-modified-id=\"Обучение-классических-моделей-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Обучение классических моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выводы-по-результатам-экспериментов\" data-toc-modified-id=\"Выводы-по-результатам-экспериментов-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span><strong>Выводы по результатам экспериментов</strong></a></span></li></ul></li><li><span><a href=\"#Обучение-модели-BERT\" data-toc-modified-id=\"Обучение-модели-BERT-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение модели BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Анализ-модели-BERT\" data-toc-modified-id=\"Анализ-модели-BERT-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Анализ модели BERT</a></span></li></ul></li></ul></li><li><span><a href=\"#Итоговые-выводы\" data-toc-modified-id=\"Итоговые-выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Итоговые выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ознакомление с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SelectKBest, chi2\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Глубокое обучение\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "# Импорт базовых библиотек\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP и обработка текста\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Машинное обучение\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (f1_score, classification_report, \n",
    "                           confusion_matrix, precision_recall_curve)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Глубокое обучение\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Трансформеры\n",
    "from transformers import (BertTokenizer, BertForSequenceClassification,\n",
    "                         Trainer, TrainingArguments, AutoModelForSequenceClassification,\n",
    "                         AutoTokenizer, get_linear_schedule_with_warmup,\n",
    "                         get_cosine_schedule_with_warmup, AutoConfig)\n",
    "\n",
    "# Вспомогательные\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import loguniform, randint\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import swifter  # Для ускорения apply\n",
    "\n",
    "# Загрузка ресурсов NLTK\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)  \n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Настройки\n",
    "RANDOM_STATE = 42\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Фиксация воспроизводимости\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Проверка GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "else:\n",
    "    print(\"CUDA недоступно, будет использоваться CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл /data/toxic_comments.csv не найден. Загружаем данные из https://code.s3.yandex.net/datasets/toxic_comments.csv...\n",
      "Все данные загружены успешно.\n"
     ]
    }
   ],
   "source": [
    "# Определяем пути к локальным файлам\n",
    "pth_df = '/data/toxic_comments.csv'                  \n",
    "\n",
    "# Определяем URL для альтернативной загрузки\n",
    "url_df = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'\n",
    "\n",
    "# Функция для загрузки данных\n",
    "def load_data(local_path, url, sep=','):\n",
    "    if os.path.exists(local_path):\n",
    "        print(f'Загрузка данных из {local_path}...')\n",
    "        return pd.read_csv(local_path, sep=sep)\n",
    "    else:\n",
    "        print(f'Файл {local_path} не найден. Загружаем данные из {url}...')\n",
    "        return pd.read_csv(url, sep=sep)\n",
    "\n",
    "# Загружаем данные\n",
    "try:\n",
    "    df = load_data(pth_df, url_df)\n",
    "    print('Все данные загружены успешно.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Произошла ошибка при загрузке данных: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/toxic_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Первые 5 строк данных:\")\n",
    "display(df.head())  # Отображаем первые 5 строк\n",
    "print(\"Последние 5 строк данных:\")\n",
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Информация о DataFrame:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Статистическое описание данных:\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество дубликатов\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим столбец Unnamed: 0\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Загрузка и проверка данных**  \n",
    "   - Данные успешно загружены из файла `toxic_comments.csv`.  \n",
    "   - Размер данных: **159 292 строки × 3 столбца**.  \n",
    "   - Пропуски и дубликаты отсутствуют.\n",
    "   - \n",
    "2. **Структура данных**  \n",
    "   - `Unnamed: 0` — технический столбец (удален).  \n",
    "   - `text` — тексты комментариев (тип `object`).  \n",
    "   - `toxic` — бинарный целевой признак (10.16% — токсичные комментарии).\n",
    "   - \n",
    "3. **Обнаруженные особенности**  \n",
    "   - Наблюдается **дисбаланс классов** (90.84% vs 10.16%).  \n",
    "   - Требуется предобработка текста (очистка, лемматизация)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполним базовую очистку текста\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Базовая очистка текста с сохранением важных для BERT элементов:\n",
    "    - пунктуация\n",
    "    - эмотиконы\n",
    "    - регистр (если используется cased-модель)\n",
    "    \"\"\"\n",
    "    # Удаление HTML-тегов\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Удаление URL\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '[URL]', text)\n",
    "  \n",
    "    # Замена переносов строк и табуляций на пробелы\n",
    "    text = re.sub(r'[\\n\\t\\r]+', ' ', text)\n",
    "\n",
    "    # Удаление IP-адресов\n",
    "    text = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', '[IP]', text)\n",
    "\n",
    "    # Удаление email-адресов\n",
    "    text = re.sub(r'\\S+@\\S+', '[EMAIL]', text)\n",
    "    \n",
    "    # Удаление лишних пробелов\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "    \n",
    "    # Удаление спецсимволов, кроме основных пунктуационных\n",
    "    text = re.sub(r'[^\\w\\s.,!?а-яА-ЯёЁ-]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Применяем очистку к данным\n",
    "df['text_clean'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Удаляем исходный столбец\n",
    "df = df.drop(columns=['text'])\n",
    "\n",
    "# Проверяем результат\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка стоп-слов\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    Конвертирует POS-теги из Penn Treebank в формат WordNet.\n",
    "    \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # По умолчанию считаем существительным\n",
    "\n",
    "def preprocess_classic(text):\n",
    "    \"\"\"\n",
    "    Предобработка текста для классических моделей:\n",
    "    - приведение к нижнему регистру\n",
    "    - удаление спецсимволов\n",
    "    - токенизация\n",
    "    - лемматизация с учетом POS-тегов\n",
    "    - удаление стоп-слов\n",
    "    \"\"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Удаление всех символов, кроме букв, цифр и основных знаков препинания\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
    "    \n",
    "    # Токенизация\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Получение POS-тегов\n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    # Инициализация лемматизатора\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Лемматизация с учетом POS-тегов и фильтрация стоп-слов\n",
    "    processed_words = []\n",
    "    for word, tag in pos_tags:\n",
    "        if word not in stop_words and word.isalpha():  # Игнорируем стоп-слова и не-слова\n",
    "            wordnet_pos = get_wordnet_pos(tag)\n",
    "            lemma = lemmatizer.lemmatize(word, wordnet_pos)\n",
    "            processed_words.append(lemma)\n",
    "    \n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "df['text_classic'] = df['text_clean'].swifter.apply(preprocess_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# случайные примеры из df['text_clean'] и df['text_classic'] для визуальной проверки:\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"BERT: {df['text_clean'].iloc[i]}\\nClassic: {df['text_classic'].iloc[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на токсичные и нетоксичные комментарии\n",
    "toxic_texts = df[df['toxic'] == 1]['text_classic']\n",
    "non_toxic_texts = df[df['toxic'] == 0]['text_classic']\n",
    "\n",
    "# Функция для создания облака слов\n",
    "def generate_wordcloud(texts, title):\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        max_words=100\n",
    "    ).generate(' '.join(texts))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Облако слов для токсичных комментариев\n",
    "generate_wordcloud(toxic_texts, 'Частые слова в токсичных комментариях')\n",
    "\n",
    "# Облако слов для нетоксичных комментариев\n",
    "generate_wordcloud(non_toxic_texts, 'Частые слова в нетоксичных комментариях')\n",
    "\n",
    "# Анализ частотности слов\n",
    "def get_top_words(texts, n=20):\n",
    "    words = ' '.join(texts).split()\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Топ-20 слов для токсичных комментариев\n",
    "top_toxic_words = get_top_words(toxic_texts)\n",
    "print(\"Топ-20 слов в токсичных комментариях:\")\n",
    "for word, count in top_toxic_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Топ-20 слов для нетоксичных комментариев\n",
    "top_non_toxic_words = get_top_words(non_toxic_texts)\n",
    "print(\"\\nТоп-20 слов в нетоксичных комментариях:\")\n",
    "for word, count in top_non_toxic_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных с явным указанием назначения для каждой выборки\n",
    "\n",
    "# Исходные данные\n",
    "texts_for_bert = df['text_clean']       # Очищенные тексты с сохранением регистра и пунктуации (для BERT)\n",
    "texts_for_classic = df['text_classic']  # Лемматизированные тексты без стоп-слов (для классических моделей)\n",
    "labels = df['toxic']                    # Метки (общие для обоих типов моделей)\n",
    "\n",
    "# Разделение для BERT модели\n",
    "\n",
    "X_bert_train, X_bert_test, y_bert_train, y_bert_test = train_test_split(\n",
    "    texts_for_bert,  # Используем оригинальные тексты с сохраненным контекстом\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=labels  # Сохраняем баланс классов\n",
    ")\n",
    "\n",
    "# Разделение для классических моделей (LogisticRegression, RandomForest и т.д.)\n",
    "\n",
    "X_classic_train, X_classic_test, y_classic_train, y_classic_test = train_test_split(\n",
    "    texts_for_classic,  # Используем предобработанные тексты (лемматизация, lower case)\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=labels  # Сохраняем баланс классов\n",
    ")\n",
    "\n",
    "# Проверка соответствия размеров и распределения\n",
    "\n",
    "print(f\"\\nПроверка размеров выборок:\")\n",
    "print(f\"BERT Train: {len(X_bert_train)}, Test: {len(X_bert_test)}\")\n",
    "print(f\"Classic Train: {len(X_classic_train)}, Test: {len(X_classic_test)}\")\n",
    "\n",
    "print(f\"\\nПроверка распределения меток:\")\n",
    "print(f\"BERT Train - доля токсичных: {y_bert_train.mean():.4f}\")\n",
    "print(f\"BERT Test - доля токсичных: {y_bert_test.mean():.4f}\")\n",
    "print(f\"Classic Train - доля токсичных: {y_classic_train.mean():.4f}\")\n",
    "print(f\"Classic Test - доля токсичных: {y_classic_test.mean():.4f}\")\n",
    "\n",
    "# Гарантируем полное соответствие меток\n",
    "assert all(y_bert_train == y_classic_train)\n",
    "assert all(y_bert_test == y_classic_test)\n",
    "print(\"\\nПроверка соответствия меток пройдена успешно!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Векторизация текстов для классических моделей\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     max_features=50000,  \n",
    "#     ngram_range=(1, 1),  \n",
    "#     stop_words='english',\n",
    "#     sublinear_tf=True    \n",
    "# )\n",
    "\n",
    "# X_classic_train_tfidf = tfidf.fit_transform(X_classic_train)\n",
    "# X_classic_test_tfidf = tfidf.transform(X_classic_test)\n",
    "\n",
    "# print(f\"\\nРазмерность TF-IDF матрицы: {X_classic_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительная очистка текста (удаление IP-адресов и т.п.)\n",
    "def advanced_clean(text):\n",
    "    # Удаление IP-адресов\n",
    "    text = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', '', text)\n",
    "    # Удаление изолированных символов\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Удаление одиночных символов в начале строки\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def advanced_clean_bert(text):\n",
    "    # Удаляем только IP-адреса и email (остальное сохраняем)\n",
    "    text = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', '', text)  # IP\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)  # Email\n",
    "    # Удаляем лишние пробелы (но не трогаем одиночные символы)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Применяем только к text_clean (оригинальные тексты для BERT)\n",
    "df['text_clean'] = df['text_clean'].apply(advanced_clean_bert)\n",
    "\n",
    "# Для классических моделей (TF-IDF) можно оставить старую очистку\n",
    "df['text_classic'] = df['text_classic'].apply(advanced_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение классических моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация и обучение моделей с использованием Pipeline для корректной кросс-валидации\n",
    "\n",
    "# 1. LogReg + Feature Selection с TF-IDF в пайплайне\n",
    "logreg_fs = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=50000,\n",
    "        ngram_range=(1, 1),\n",
    "        stop_words='english',\n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    ('feature_selection', SelectKBest(chi2)),\n",
    "    ('model', SGDClassifier(\n",
    "        loss='log_loss',\n",
    "        penalty='elasticnet',\n",
    "        class_weight='balanced',\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "logreg_params = {\n",
    "    'tfidf__max_features': [30000, 50000],\n",
    "    'feature_selection__k': [10000, 15000, 20000],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01],\n",
    "    'model__l1_ratio': [0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "# 2. LightGBM с TF-IDF в пайплайне\n",
    "lgbm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=50000,\n",
    "        ngram_range=(1, 1),\n",
    "        stop_words='english'\n",
    "    )),\n",
    "    ('lgbm', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        force_row_wise=True,\n",
    "        verbose=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "lgbm_params = {\n",
    "    'lgbm__num_leaves': [31, 63, 127],\n",
    "    'lgbm__max_depth': [5, 7, 10],\n",
    "    'lgbm__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'lgbm__n_estimators': [200, 300, 500],\n",
    "    'lgbm__min_child_samples': [20, 50],\n",
    "    'lgbm__reg_alpha': [0, 0.1],\n",
    "    'lgbm__reg_lambda': [0, 0.1],\n",
    "    'lgbm__class_weight': ['balanced', {0: 1, 1: 3}]\n",
    "}\n",
    "\n",
    "# 3. LinearSVC с TF-IDF в пайплайне\n",
    "svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=50000,\n",
    "        ngram_range=(1, 1),\n",
    "        stop_words='english'\n",
    "    )),\n",
    "    ('model', LinearSVC(\n",
    "        class_weight={0: 1, 1: 2.5},\n",
    "        random_state=RANDOM_STATE,\n",
    "        dual=False,\n",
    "        loss='squared_hinge',\n",
    "        max_iter=2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "svm_params = {\n",
    "    'model__C': [0.3, 0.5, 0.7],\n",
    "    'model__tol': [1e-4, 1e-5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pipeline, params, X_train, y_train, name):\n",
    "    \"\"\"Функция для обучения модели с кросс-валидацией\"\"\"\n",
    "    print(f\"\\n=== Обучение {name} ===\")\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        params,\n",
    "        n_iter=5,\n",
    "        scoring='f1',\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    search.fit(X_train, y_train)\n",
    "    training_time = time.time() - start\n",
    "    \n",
    "    print(f\"Лучшие параметры: {search.best_params_}\")\n",
    "    print(f\"Лучший F1 на кросс-валидации: {search.best_score_:.4f}\")\n",
    "    print(f\"Время обучения: {training_time:.1f} сек\")\n",
    "    \n",
    "    return search.best_estimator_, search.best_score_, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модели на тренировочных данных (без использования тестовой выборки)\n",
    "models = {\n",
    "    'LogReg': (logreg_fs, logreg_params),\n",
    "    'LightGBM': (lgbm, lgbm_params),\n",
    "    'LinearSVM': (svm, svm_params)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_f1 = 0\n",
    "best_model_name = ''\n",
    "best_model = None\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    best_current_model, cv_f1, t_time = train_model(\n",
    "        model, params,\n",
    "        X_classic_train, y_classic_train,  # Используем исходные тексты\n",
    "        name\n",
    "    )\n",
    "    results[name] = {\n",
    "        'model': best_current_model,\n",
    "        'cv_f1': cv_f1,\n",
    "        'time': t_time\n",
    "    }\n",
    "    \n",
    "    if cv_f1 > best_f1:\n",
    "        best_f1 = cv_f1\n",
    "        best_model_name = name\n",
    "        best_model = best_current_model\n",
    "\n",
    "# Выводим результаты кросс-валидации\n",
    "print(\"\\nИтоговые результаты кросс-валидации:\")\n",
    "print(f\"{'Модель':<15} {'F1-мера (CV)':<12} {'Время (сек)':<10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"{name:<15} {result['cv_f1']:<12.4f} {result['time']:<10.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцениваем только лучшую модель на тестовой выборке\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Оценка лучшей модели ({best_model_name}) на тестовой выборке:\")\n",
    "\n",
    "# Получаем предсказания для тестовой выборки\n",
    "y_pred = best_model.predict(X_classic_test)\n",
    "test_f1 = f1_score(y_classic_test, y_pred)\n",
    "\n",
    "print(classification_report(y_classic_test, y_pred, digits=4))\n",
    "print(f\"F1 на тестовой выборке: {test_f1:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем confusion matrix\n",
    "cm = confusion_matrix(y_classic_test, y_pred)\n",
    "\n",
    "# Выводим сырые данные матрицы\n",
    "print(\"=\"*50)\n",
    "print(\"Confusion Matrix Raw Data:\")\n",
    "print(cm)\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Выводим классификационный отчет\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_classic_test, y_pred, target_names=['Non-Toxic', 'Toxic']))\n",
    "\n",
    "# Визуализируем матрицу ошибок\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                 cbar=False, linewidths=0.5, linecolor='gray')\n",
    "\n",
    "# Настраиваем подписи\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "ax.xaxis.set_ticklabels(['Non-Toxic', 'Toxic'], fontsize=10)\n",
    "ax.yaxis.set_ticklabels(['Non-Toxic', 'Toxic'], fontsize=10)\n",
    "ax.set_title('Confusion Matrix for Toxic Comments Detection', fontsize=14, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выводим интерпретацию\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Matrix Interpretation:\")\n",
    "print(f\"True Negatives (TN): {cm[0,0]} - Корректно предсказанные нетоксичные комментарии\")\n",
    "print(f\"False Positives (FP): {cm[0,1]} - Нетоксичные комментарии, ошибочно помеченные как токсичные\")\n",
    "print(f\"False Negatives (FN): {cm[1,0]} - Токсичные комментарии, пропущенные моделью\")\n",
    "print(f\"True Positives (TP): {cm[1,1]} - Корректно обнаруженные токсичные комментарии\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Выводы по результатам экспериментов**\n",
    "\n",
    " 1. Сравнение моделей\n",
    "| Модель      | F1-мера (CV) | Время (сек) |\n",
    "|-------------|--------------|-------------|\n",
    "| **LogReg**  | 0.7063       | 9.0         |\n",
    "| **LightGBM**| 0.7645       | 53.0        |\n",
    "| **LinearSVM**| **0.7835**  | **8.4**     |\n",
    "\n",
    "- **LinearSVM** показала наилучший результат (F1=0.7835) при минимальном времени обучения (8.4 сек).\n",
    "- LightGBM уступает в скорости (53 сек), но превосходит LogReg по качеству.\n",
    "- Линейные методы (SVM, LogReg) эффективны для текстовых данных с TF-IDF.\n",
    "\n",
    "---\n",
    "\n",
    " 2. Качество классификации\n",
    "**Для класса Toxic (1):**\n",
    "- **Precision = 0.81** → Из предсказанных токсичных комментариев 81% верны.\n",
    "- **Recall = 0.75** → Пропущено **25%** токсичных комментариев (FN=817).\n",
    "- **F1 = 0.7783** → Баланс между точностью и полнотой.\n",
    "\n",
    "**Для класса Non-Toxic (0):**\n",
    "- Идеальные метрики (F1=0.98) из-за дисбаланса данных (28.6k vs 3.2k).\n",
    "\n",
    "---\n",
    "\n",
    " 3. Проблемные зоны\n",
    "- **False Negatives (FN)**: 817 токсичных комментариев не обнаружены (риск пропуска вредного контента).\n",
    "- **False Positives (FP)**: 562 нетоксичных комментария помечены как токсичные (ложные срабатывания увеличивают нагрузку на модераторов).\n",
    "\n",
    "---\n",
    "\n",
    " 4. Рекомендации\n",
    "1. **Улучшение Recall для Toxic класса**:\n",
    "   - Повысить вес класса 1 (`class_weight`).\n",
    "   - Применить техники oversampling (SMOTE) или ансамблирование.\n",
    "   - Настроить порог классификации (threshold tuning).\n",
    "\n",
    "2. **Эксперименты**:\n",
    "   - Тестировать BERT/Transformer-модели для контекстного анализа.\n",
    "   - Добавить семантические признаки (например, эмбеддинги).\n",
    "\n",
    "3. **Интерпретируемость**:\n",
    "   - Использовать LightGBM для анализа важности признаков.\n",
    "\n",
    "---\n",
    "\n",
    " 5. Риски\n",
    "- **Высокий FP**: Увеличивает трудозатраты на ручную проверку.\n",
    "- **Низкий Recall для Toxic**: Риск нарушения модерации контента.\n",
    "\n",
    "---\n",
    "\n",
    "**Итог**: LinearSVM — оптимальный выбор для базового решения. Для production-системы требуется:  \n",
    "✅ **Приоритет**: Снижение FN (улучшение Recall для Toxic).  \n",
    "⚠️ **Компромисс**: Возможное увеличение FP при тонкой настройке.  \n",
    "🔍 **Дополнение**: Исследование контекстно-зависимых моделей (BERT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True  # Включаем оптимизацию cuDNN\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  # Разрешаем TensorFloat-32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, inputs, targets, weights):\n",
    "        # Вычисляем кросс-энтропию без reduction\n",
    "        loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        # Умножаем на веса и усредняем\n",
    "        return (loss * weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBertDataset(Dataset):\n",
    "    def __init__(self, texts, labels, weights, tokenizer, max_len):\n",
    "        self.texts = texts.reset_index(drop=True)\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "        self.weights = weights\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            'weights': self.weights[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bert_data(texts, labels, tokenizer, max_len=128):\n",
    "    # Балансировка классов\n",
    "    classes = np.unique(labels)\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
    "    sample_weights = torch.tensor(\n",
    "        [class_weights[list(classes).index(label)] for label in labels], \n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    return WeightedBertDataset(texts, labels, sample_weights, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Загрузка модели с правильной настройкой\n",
    "model_name = \"unitary/toxic-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 2. Настройка конфигурации\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = 2  # Бинарная классификация\n",
    "config.hidden_dropout_prob = 0.1\n",
    "config.attention_probs_dropout_prob = 0.1\n",
    "\n",
    "# 3. Загрузка модели с обработкой несовпадения размеров\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True  # Критически важный параметр\n",
    ").to(device)\n",
    "\n",
    "# 4. Дополнительная инициализация (опционально)\n",
    "import torch.nn as nn\n",
    "model.classifier = nn.Linear(768, 2).to(device)  # Явная переинициализация\n",
    "\n",
    "print(\"Модель готова к обучению!\")\n",
    "print(f\"Входные примеры: {model.num_parameters()/1e6:.1f}M параметров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 64  \n",
    "GRAD_ACCUM_STEPS = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = prepare_bert_data(X_bert_train, y_bert_train, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,  \n",
    "    persistent_workers=False  \n",
    ")\n",
    "\n",
    "test_dataset = prepare_bert_data(X_bert_test, y_bert_test, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE*2,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    persistent_workers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ======== Оптимизированный цикл обучения ========\n",
    "scaler = GradScaler()  # Для mixed precision\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=2e-5,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Замораживаем слои (кроме классификатора) на первых эпохах\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS // GRAD_ACCUM_STEPS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1*total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "criterion = WeightedLoss()\n",
    "\n",
    "best_f1 = 0\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Размораживаем все слои после 1-й эпохи\n",
    "    if epoch == 1:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # ===== Обучение =====\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    train_preds, train_truths = [], []\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_mask'].to(device)\n",
    "            )\n",
    "            loss = criterion(\n",
    "                outputs.logits,\n",
    "                batch['labels'].to(device),\n",
    "                batch['weights'].to(device)\n",
    "            ) / GRAD_ACCUM_STEPS\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % GRAD_ACCUM_STEPS == 0 or (i + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item() * GRAD_ACCUM_STEPS\n",
    "        train_preds.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "        train_truths.extend(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_f1 = f1_score(train_truths, train_preds, pos_label=1)\n",
    "    \n",
    "    # ===== Валидация =====\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_truths = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch['input_ids'].to(device),\n",
    "                    attention_mask=batch['attention_mask'].to(device)\n",
    "                )\n",
    "                val_loss += criterion(\n",
    "                    outputs.logits,\n",
    "                    batch['labels'].to(device),\n",
    "                    batch['weights'].to(device)\n",
    "                ).item()\n",
    "            val_preds.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "            val_truths.extend(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(test_loader)\n",
    "    val_f1 = f1_score(val_truths, val_preds, pos_label=1)\n",
    "    \n",
    "    # ===== Вывод метрик =====\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # ===== Сохранение лучшей модели =====\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_bert_model.pt')\n",
    "        no_improve = 0\n",
    "        print(f\"Model improved! Saved with F1: {val_f1:.4f}\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"No improvement for {patience} epochs. Stopping...\")\n",
    "            break\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best Val F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем предсказания и истинные метки\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Прогнозирование\"):\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device)\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        all_preds.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "# Вычисляем метрики\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "clf_report = classification_report(all_labels, all_preds, \n",
    "                                 target_names=['Non-Toxic', 'Toxic'],\n",
    "                                 digits=4,\n",
    "                                 output_dict=True)\n",
    "\n",
    "# ================== ВЫВОД ОТЧЕТА ==================\n",
    "print(\"=\"*50)\n",
    "print(\"Confusion Matrix Raw Data:\")\n",
    "print(cm)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(f\"{'':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Non-Toxic':<15} {clf_report['Non-Toxic']['precision']:<10.4f} \"\n",
    "      f\"{clf_report['Non-Toxic']['recall']:<10.4f} \"\n",
    "      f\"{clf_report['Non-Toxic']['f1-score']:<10.4f} \"\n",
    "      f\"{clf_report['Non-Toxic']['support']:<10}\")\n",
    "print(f\"{'Toxic':<15} {clf_report['Toxic']['precision']:<10.4f} \"\n",
    "      f\"{clf_report['Toxic']['recall']:<10.4f} \"\n",
    "      f\"{clf_report['Toxic']['f1-score']:<10.4f} \"\n",
    "      f\"{clf_report['Toxic']['support']:<10}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Accuracy':<15} {'':<30} {clf_report['accuracy']:.4f} {len(all_labels):<10}\")\n",
    "print(f\"{'Macro Avg':<15} {clf_report['macro avg']['precision']:<10.4f} \"\n",
    "      f\"{clf_report['macro avg']['recall']:<10.4f} \"\n",
    "      f\"{clf_report['macro avg']['f1-score']:<10.4f} \"\n",
    "      f\"{clf_report['macro avg']['support']:<10}\")\n",
    "print(f\"{'Weighted Avg':<15} {clf_report['weighted avg']['precision']:<10.4f} \"\n",
    "      f\"{clf_report['weighted avg']['recall']:<10.4f} \"\n",
    "      f\"{clf_report['weighted avg']['f1-score']:<10.4f} \"\n",
    "      f\"{clf_report['weighted avg']['support']:<10}\")\n",
    "\n",
    "# ================== ИНТЕРПРЕТАЦИЯ ==================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"F1-Score Analysis:\")\n",
    "print(f\"• Общий F1 (Macro Avg): {clf_report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"• Общий F1 (Weighted Avg): {clf_report['weighted avg']['f1-score']:.4f}\")\n",
    "print(f\"• Non-Toxic F1: {clf_report['Non-Toxic']['f1-score']:.4f}\")\n",
    "print(f\"• Toxic F1: {clf_report['Toxic']['f1-score']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Toxic', 'Toxic'], \n",
    "            yticklabels=['Non-Toxic', 'Toxic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Анализ модели BERT\n",
    "\n",
    " 1. **Ключевые метрики**\n",
    "| Метрика               | Значение  |\n",
    "|-----------------------|-----------|\n",
    "| **Accuracy**          | 0.9828    |\n",
    "| **Toxic F1**          | 0.9175    |\n",
    "| **Non-Toxic F1**      | 0.9900    |\n",
    "| **False Negatives**   | 189       |\n",
    "| **False Positives**   | 359       |\n",
    "\n",
    "---\n",
    "\n",
    " 2. **Сравнение с предыдущими моделями**\n",
    "| Модель          | Toxic F1 | FN   | FP   | Время обучения |\n",
    "|------------------|----------|------|------|----------------|\n",
    "| **LinearSVM**    | 0.7783   | 817  | 562  | 8.4 сек        |\n",
    "| **LightGBM**     | 0.7645   | -    | -    | 53 сек         |\n",
    "| **BERT**         | **0.9146** | **189** | **359** | ~8 мин       |\n",
    "\n",
    "**Преимущества BERT**:\n",
    "- **Революционное улучшение F1 для Toxic**: +17.5% относительно LinearSVM.\n",
    "- **В 4.3 раза меньше пропусков** токсичных комментариев (FN ↓ с 817 до 189).\n",
    "- **На 32% меньше ложных срабатываний** (FP ↓ с 562 до 359).\n",
    "\n",
    "---\n",
    "\n",
    " 3. **Динамика обучения**\n",
    "| Эпоха | Train Loss | Val F1    | Тренд               |\n",
    "|-------|------------|-----------|---------------------|\n",
    "| 1     | 0.0943     | 0.8482    | Старт обучения      |\n",
    "| 2     | 0.0842     | **0.9121**| Резкий рост качества|\n",
    "| 3     | 0.0406     | 0.8923    | Признаки переобучения |\n",
    "| 4     | 0.0209     | **0.9146**| Новый максимум      |\n",
    "\n",
    "**Инсайты**:\n",
    "- Модель быстро сходится (пик F1 на 2 эпохе).\n",
    "- Переобучение на 3 эпохе: Train Loss ↓, Val F1 ↓.\n",
    "- Лучшая модель сохранена на 4 эпохе, несмотря на рост Train Loss.\n",
    "\n",
    "---\n",
    "\n",
    " 4. **Рекомендации для BERT**\n",
    "1. **Оптимизация обучения**:\n",
    "   - Внедрить **early stopping** при падении Val F1.\n",
    "   - Тестировать **заморозку эмбеддингов** BERT + дообучение верхних слоёв.\n",
    "2. **Улучшение качества**:\n",
    "   - Калибровка порога классификации для баланса FP/FN.\n",
    "   - Добавить **контекстные правила** (например, блокировка определённых шаблонов токсичности).\n",
    "3. **Скорость инференса**:\n",
    "   - Экспериментировать с **квантованием модели** или **DistilBERT**.\n",
    "   - Увеличить батч-сайз при прогнозировании (сейчас 10.46 примеров/сек)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговые выводы\n",
    "\n",
    " 1. **Сравнение всех моделей**\n",
    " \n",
    "| Критерий          | LinearSVM         | LightGBM          | BERT              |\n",
    "|--------------------|-------------------|-------------------|-------------------|\n",
    "| **Скорость**       | 🟢 Лучшая (8.4 сек)| 🔴 Самая медленная | 🟡 Умеренная      |\n",
    "| **Toxic F1**       | 0.7783            | 0.7645            | **0.9146**        |\n",
    "| **Интерпретируемость** | 🟢 Высокая     | 🟢 Средняя        | 🔴 Низкая         |\n",
    "| **Масштабируемость** | 🟢 Для больших данных | 🟡 Ограничено | 🔴 Требует GPU   |\n",
    "\n",
    "---\n",
    "\n",
    " 2. **Рекомендации для проекта**\n",
    "- **Выбор модели**:\n",
    "  - **BERT** — для production, если критично качество и есть GPU-ресурсы.\n",
    "  - **LinearSVM** — для MVP или систем с ограниченными мощностями.\n",
    "- **Доработки**:\n",
    "  - Для BERT: оптимизировать скорость инференса (квантование, батчинг).\n",
    "  - Для LinearSVM: повысить Recall через oversampling или ансамбли.\n",
    "- **Риски**:\n",
    "  - **BERT**: Высокие затраты на обслуживание.\n",
    "  - **LinearSVM**: Риск пропуска токсичного контента (FN=817).\n",
    "\n",
    "---\n",
    "\n",
    " 3. **Стратегия внедрения**\n",
    "1. **Пилотная фаза**:\n",
    "   - Запустить BERT в тестовом режиме с мониторингом FP/FN.\n",
    "   - Сравнить нагрузку на инфраструктуру с текущими моделями.\n",
    "2. **Оптимизация**:\n",
    "   - Реализовать кэширование предсказаний для частых запросов.\n",
    "   - Добавить фильтр-правила для очевидных случаев (маты, угрозы).\n",
    "3. **Долгосрочный план**:\n",
    "   - Переход на **DistilBERT** или **TinyBERT** для баланса скорости/качества.\n",
    "   - Внедрение активного обучения для улучшения модели на реальных данных.\n",
    "\n",
    "---\n",
    "\n",
    "**Финальный вердикт**:  \n",
    "BERT — безусловный лидер по качеству, но требует значительных ресурсов.  \n",
    "Для стартапов или проектов с ограничениями LinearSVM остается жизнеспособной альтернативой.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
