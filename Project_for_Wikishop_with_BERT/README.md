# Классификация токсичных комментариев для интернет-магазина «Викишоп»

## Описание проекта

Проект разработан для автоматического обнаружения токсичных комментариев в системе пользовательских правок описаний товаров. Основная задача — создать модель, способную классифицировать комментарии на позитивные и негативные с целевым значением F1-меры не менее 0.75. Это позволит отправлять токсичные комментарии на модерацию, улучшая качество контента.

**Исходные данные:**
- Датасет содержит 159,292 комментария с разметкой токсичности.
- Столбцы:
  - `text`: исходный текст комментария.
  - `toxic`: бинарный признак (1 — токсичный, 0 — нетоксичный).
- Наблюдается дисбаланс классов: 10.16% токсичных комментариев.

**Основные этапы работы:**
1. **Подготовка данных:**
   - Очистка текста (удаление HTML-тегов, URL, email и т.д.).
   - Лемматизация и удаление стоп-слов для классических моделей.
   - Сохранение контекста для BERT.

2. **Обучение моделей:**
   - Классические модели (LinearSVM, LightGBM) с TF-IDF.
   - Fine-tuning предобученной BERT-модели.

3. **Оценка и сравнение моделей:**
   - Анализ метрик (F1, Precision, Recall).
   - Оптимизация для уменьшения False Negatives.

**Используемые библиотеки:**
- `pandas`, `numpy` — обработка данных.
- `nltk`, `re` — предобработка текста.
- `sklearn` — классические модели и метрики.
- `transformers`, `torch` — работа с BERT.
- `matplotlib`, `seaborn` — визуализация.

## Ключевые выводы

1. **Результаты моделей:**
   - **LinearSVM:** F1 = 0.7835 (лучшая среди классических моделей).
   - **LightGBM:** F1 = 0.7645.
   - **BERT:** F1 = 0.9146 (наивысшее качество).

2. **Сравнение моделей:**
   - **BERT** показал значительное улучшение:
     - Уменьшение False Negatives на 77% (с 817 до 189).
     - Увеличение F1 для токсичных комментариев на 17.5%.
   - **LinearSVM** — оптимальный выбор для систем с ограниченными ресурсами.



## Практическая значимость

Проект демонстрирует эффективность современных NLP-методов (BERT) для задач классификации текста. Внедрение модели позволит:
- Автоматизировать модерацию комментариев.
- Снизить нагрузку на ручную модерацию.
- Улучшить пользовательский опыт за счет быстрого обнаружения токсичного контента.
